{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Flatten,Dropout,BatchNormalization,Conv2D,MaxPool2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras import layers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = 'data'\n",
    "LOSS_THRESHOLD = 0.2\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "input_shape = (200, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DATA GENERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182700 images belonging to 51 classes.\n",
      "Found 20300 images belonging to 51 classes.\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(os.listdir(training_dir))\n",
    "\n",
    "# =====================================================================\n",
    "# DATA GENERATORS\n",
    "data_generator = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    brightness_range=[0.8, 1.0],\n",
    "    zoom_range=[1.0, 1.2],\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(200, 200),\n",
    "    shuffle=True,\n",
    "    seed=13,\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(200, 200),\n",
    "    shuffle=True,\n",
    "    seed=13,\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imagenet_model():\n",
    "    inception_v3_model = keras.applications.inception_v3.InceptionV3(\n",
    "        input_shape=(200, 200, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    inception_v3_model.summary()\n",
    "\n",
    "    inception_output_layer = inception_v3_model.get_layer('mixed7')\n",
    "    print('Inception model output shape:', inception_output_layer.output_shape)\n",
    "\n",
    "    inception_output = inception_v3_model.output\n",
    "\n",
    "    layers = layers.GlobalAveragePooling2D()(inception_output)\n",
    "    layers = layers.Dense(1024, activation='relu')(layers)\n",
    "    layers = layers.Dense(51, activation='softmax')(layers)\n",
    "    \n",
    "    model = Model(inception_v3_model.input, x)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['acc']\n",
    "    )\n",
    "    \n",
    "    for layer in model.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[249:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classic_model():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(Input(shape=input_shape))\n",
    "    layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_classic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-aaad061243fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_classic_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_classic_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = create_classic_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_loss') <= LOSS_THRESHOLD and logs.get('val_acc') >= ACCURACY_THRESHOLD:\n",
    "            print(\"\\nReached\", ACCURACY_THRESHOLD * 100, \"accuracy, Stopping!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "callback = ModelCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=200,\n",
    "    validation_steps=50,\n",
    "    epochs=50,\n",
    "    callbacks=[callback]\n",
    ")\n",
    "model.save('transferlearning.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
